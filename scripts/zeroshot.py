# -*- coding: utf-8 -*-
"""Copy of finetuning NLP LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18rU09Wm2X1zEiz02noNoTj7k1w-lOvlY
"""

"""
This script performs zeroshot testing on a new dataset using the Roberta-base model
"""

# load necessary modules
import pandas as pd
from transformers import pipeline
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import os


df = pd.read_csv("./data/electronics_reviews.csv")
#df.head() #get a snippet of the data

# check for distinct sentiments
#df['sentiment'].unique()

#chose the roberta-base model since the sentiments are in 3 classes
zero_shot_model = pipeline("text-classification", model="cardiffnlp/twitter-roberta-base-sentiment")

# a dictionary that points each sentiment label to a numeral
# 'negative': 0, 'neutral': 1, 'positive': 2
label_map = {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}

# test the roberta-base model on the reviews
preds = [label_map[zero_shot_model(text)[0]['label']] for text in tqdm(df['review_text'])]

# view the roberta-base model initial predictions
#print(preds)

# create a dictionary for the numerical labels for each actual unique sentiment
label_int = {'negative': 0, 'neutral': 1, 'positive': 2}
# add a new column, label, and map the integer value for each sentiment
df['label'] = df['sentiment'].map(label_int)

# print out the base model's classification report and confusion matrix
print(classification_report(df['label'], preds, target_names=["Negative", "Neutral", "Positive"]))

cm = confusion_matrix(df['label'], preds)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], 
            yticklabels=['Negative', 'Neutral', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix For Finetuned Roberta Model')
os.makedirs("./plots", exist_ok=True)
plt.savefig("./plots/Roberta_base_model_confusion_matrix_on_whole_dataset.png", dpi=300, bbox_inches='tight')  # Save the plot
plt.show()

# Add predictions to dataFrame
df['pred'] = preds

# Filter misclassified reviews
errors = df[df['label'] != df['pred']]

# Show top 10 error cases
sample_errors = errors[['review_text', 'label', 'pred']].sample(10, random_state=42)
print(sample_errors.to_string(index=False))

